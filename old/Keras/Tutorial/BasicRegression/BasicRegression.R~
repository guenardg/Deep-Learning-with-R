##
### Tutorial: Basic Regression
##
## In a regression problem, we aim to predict the output of a
## continuous value, like a price or a probability. Contrast this with
## a classification problem, where we aim to predict a discrete label
## (for example, where a picture contains an apple or an orange).
##
## This notebook builds a model to predict the median price of homes
## in a Boston suburb during the mid-1970s. To do this, we’ll provide
## the model with some data points about the suburb, such as the crime
## rate and the local property tax rate. 
##
library(keras)
##
### The Boston Housing Prices dataset
##
## The Boston Housing Prices dataset is accessible directly from keras.
if(FALSE) {
    boston_housing <- dataset_boston_housing()
    save(boston_housing,file="../../Data/boston_housing.rda")
} else
    load(file="../../Data/boston_housing.rda")
##
c(train_data, train_labels) %<-% boston_housing$train
c(test_data, test_labels) %<-% boston_housing$test
##
## This dataset is much smaller than the others we’ve worked with so
## far: it has 506 total examples that are split between 404 training
## examples and 102 test examples:
paste0("Training entries: ", length(train_data), ", labels: ", length(train_labels))
##
## The dataset contains 13 different features:
##    Per capita crime rate.
##    The proportion of residential land zoned for lots over 25,000 square feet.
##    The proportion of non-retail business acres per town.
##    Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
##    Nitric oxides concentration (parts per 10 million).
##    The average number of rooms per dwelling.
##    The proportion of owner-occupied units built before 1940.
##    Weighted distances to five Boston employment centers.
##    Index of accessibility to radial highways.
##    Full-value property-tax rate per $10,000.
##    Pupil-teacher ratio by town.
##    1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.
##    Percentage lower status of the population.
##
## Each one of these input data features is stored using a different
## scale. Some features are represented by a proportion between 0 and
## 1, other features are ranges between 1 and 12, some are ranges
## between 0 and 100, and so on.
##
train_data[1L,] # Display sample features, notice the different scales
##
## Let’s add column names for better data inspection.
library(tibble)
##
column_names <- c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 
                  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT')
train_df <- as_tibble(train_data)
colnames(train_df) <- column_names
##
train_df
##
### Labels
##
## The labels are the house prices in thousands of dollars. (You may
## notice the mid-1970s prices.)
##
train_labels[1L:10L] ## Display first 10 entries
##
### Normalize features
##
## It’s recommended to normalize features that use different scales
## and ranges. Although the model might converge without feature
## normalization, it makes training more difficult, and it makes the
## resulting model more dependant on the choice of units used in the
## input.
##
## Test data is *not* used when calculating the mean and std.
##
## Normalize training data
train_data <- scale(train_data) 
##
## Use means and standard deviations from training set to normalize test set
col_means_train <- attr(train_data, "scaled:center") 
col_stddevs_train <- attr(train_data, "scaled:scale")
test_data <- scale(test_data, center = col_means_train, scale = col_stddevs_train)
##
train_data[1L,] ## First training sample, normalized
##
### Create the model
##
## Let’s build our model. Here, we’ll use a sequential model with two
## densely connected hidden layers, and an output layer that returns a
## single, continuous value. The model building steps are wrapped in a
## function, build_model, since we’ll create a second model, later on.
##
build_model <- function() {
    model <- keras_model_sequential() %>%
        layer_dense(units = 64, activation = "relu",
                    input_shape = dim(train_data)[2]) %>%
        layer_dense(units = 64, activation = "relu") %>%
        layer_dense(units = 1)
    ##
    model %>%
        compile(
            loss = "mse",
            optimizer = optimizer_rmsprop(),
            metrics = list("mean_absolute_error")
        )
    ##
    return(model)
}
##
model <- build_model()
model %>% summary()
##
### Train the model
##
## The model is trained for 500 epochs, recording training and
## validation accuracy in a keras_training_history object. We also
## show how to use a custom callback, replacing the default training
## output by a single dot per epoch.
##
## Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
    on_epoch_end = function(epoch, logs) {
        if (epoch %% 80 == 0) cat("\n")
        cat(".")
    }
)
##
epochs <- 500L
##
## Fit the model and store training stats
history <- model %>%
    fit(
        train_data,
        train_labels,
        epochs = epochs,
        validation_split = 0.2,
        verbose = 0,
        callbacks = list(print_dot_callback)
    )
##
## Now, we visualize the model’s training progress using the metrics
## stored in the history variable. We want to use this data to
## determine how long to train before the model stops making progress.
##
library(ggplot2)
##
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
    coord_cartesian(ylim = c(0, 5))
##
## This graph shows little improvement in the model after about 200
## epochs. Let’s update the fit method to automatically stop training
## when the validation score doesn’t improve. We’ll use a callback
## that tests a training condition for every epoch. If a set amount of
## epochs elapses without showing improvement, it automatically stops
## the training.
##
# The patience parameter is the amount of epochs to check for improvement.
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)
##
model <- build_model()
history <- model %>%
    fit(
        train_data,
        train_labels,
        epochs = epochs,
        validation_split = 0.2,
        verbose = 0,
        callbacks = list(early_stop, print_dot_callback)
    )
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
    coord_cartesian(xlim = c(0, 150), ylim = c(0, 5))
##
## The graph shows the average error is about $2,500 dollars. Is this
## good? Well, $2,500 is not an insignificant amount when some of the
## labels are only $15,000.
##
## Let’s see how did the model performs on the test set:
c(loss, mae) %<-% (model %>% evaluate(test_data, test_labels, verbose = 0))
##
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae * 1000))
##
### Predict
##
## Finally, predict some housing prices using data in the testing set:
test_predictions <- model %>% predict(test_data)
test_predictions[,1L]
##
### Conclusion
##
## This notebook introduced a few techniques to handle a regression
## problem.
## > Mean Squared Error (MSE) is a common loss function used for
##   regression problems (different than classification problems).
## > Similarly, evaluation metrics used for regression differ from
##   classification. A common regression metric is Mean Absolute Error
##   (MAE).
## > When input data features have values with different ranges, each
##   feature should be scaled independently.
## > If there is not much training data, prefer a small network with
##   few hidden layers to avoid overfitting.
## > Early stopping is a useful technique to prevent overfitting.
##
rm(boston_housing,train_data,train_labels,test_data,test_labels,col_means_train,col_stddevs_train)
if(FALSE) {
    load(file="../../Data/boston_housing.rda")
    c(train_data, train_labels) %<-% boston_housing$train
    c(test_data, test_labels) %<-% boston_housing$test
    train_data <- scale(train_data)
    col_means_train <- attr(train_data, "scaled:center") 
    col_stddevs_train <- attr(train_data, "scaled:scale")
    test_data <- scale(test_data, center = col_means_train, scale = col_stddevs_train)
}
##
